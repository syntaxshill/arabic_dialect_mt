services:
  gemini-backtranslation:
    environment:
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./:/workspace
    working_dir: /workspace
    command: >
      bash -c "pip install google-generativeai &&
                python -m src.benchmark_llms --data_file data/subtask_3_mono_MSA.txt --gemini"
  
  run-gemini:
    environment:
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./:/workspace
    working_dir: /workspace
    command: >
      bash -c "pip install google-generativeai &&
                python -m src.benchmark_llms --data_file data/osact6_task2_test.csv --gemini"
  
  run-gpt:
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./:/workspace
    working_dir: /workspace
    command: "python -m src.benchmark_llms --data_file data/osact6_task2_test.csv --gpt"
  
  run-aya:
    environment:
      - HF_TOKEN=${HF_TOKEN}
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./:/workspace
    working_dir: /workspace
    command: "python -m src.benchmark_llms --data_file data/osact6_task2_test.csv --output_dir out --metric_dir metrics --aya"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0", "1"]
              capabilities: [gpu]
  test-cuda:
    image: nvcr.io/nvidia/cuda:12.1.1-cudnn8-devel-ubuntu20.04
    command: nvidia-smi
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
